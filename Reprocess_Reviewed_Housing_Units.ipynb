{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update attributes on reviewed parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from arcgis import GIS\n",
    "import numpy as np\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# show all columns\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# pd.DataFrame.spatial.from_featureclass(???)\n",
    "# df.spatial.to_featureclass(location=???,sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path output folder\n",
    "outputs = '.\\\\Outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output gdb\n",
    "outputs = '.\\\\Outputs'\n",
    "gdb = os.path.join(outputs, \"wfrc_hui_20211101.gdb\")\n",
    "if not arcpy.Exists(gdb):\n",
    "    arcpy.CreateFileGDB_management(outputs, \"wfrc_hui_20211101.gdb\")\n",
    "    \n",
    "scratch = os.path.join(outputs, \"scratch_rp.gdb\")\n",
    "if not arcpy.Exists(scratch):\n",
    "    arcpy.CreateFileGDB_management(outputs, \"scratch_rp.gdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391825, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "hui = r\"E:\\Projects\\Housing-Unit-Inventory\\Review\\reviewed.gdb\\hui_reviewed_and_nonreviewed_parcels\"\n",
    "hui_sdf = pd.DataFrame.spatial.from_featureclass(hui)\n",
    "hui_sdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OBJECTID', 'PARCEL_ID', 'TYPE_WFRC', 'SUBTYPE_WFRC', 'NOTE', 'IS_OUG',\n",
       "       'CITY', 'SUBREGION', 'COUNTY', 'HOUSE_CNT', 'ADDR_CNT', 'UNIT_COUNT',\n",
       "       'PARCEL_COUNT', 'FLAG', 'DUA', 'FLOORS_CNT', 'PARCEL_ACRES',\n",
       "       'BLDG_SQFT', 'TOTAL_MKT_VALUE', 'BUILT_YR', 'BUILT_DECADE', 'UNIT_ID',\n",
       "       'ADJUSTED', 'REVIEWED', 'MERGE_SRC', 'SHAPE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hui_sdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regenerate unique building id\n",
    "hui_sdf['UNIT_ID'] = hui_sdf.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the floor counts\n",
    "hui_sdf.loc[(hui_sdf['FLOORS_CNT'] < 1) | (hui_sdf['FLOORS_CNT'].isnull() == True), 'FLOORS_CNT'] = 1\n",
    "hui_sdf['FLOORS_CNT'] = hui_sdf['FLOORS_CNT'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 26)\n",
      "(391730, 26)\n"
     ]
    }
   ],
   "source": [
    "# remove parcels with zero housing units and store them for later\n",
    "vacant = hui_sdf[hui_sdf['UNIT_COUNT'] == 0].copy()\n",
    "vacant.spatial.to_featureclass(location=os.path.join(scratch, 'vacant'),sanitize_columns=False)\n",
    "hui_sdf = hui_sdf[~(hui_sdf['UNIT_COUNT'] == 0)].copy()\n",
    "\n",
    "print(vacant.shape)\n",
    "print(hui_sdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove parcels from other categories\n",
    "office = hui_sdf[hui_sdf['TYPE_WFRC'] == 'office'].copy()\n",
    "group_quarters = hui_sdf[hui_sdf['TYPE_WFRC'] == 'group_quarters'].copy()\n",
    "retail = hui_sdf[hui_sdf['TYPE_WFRC'] == 'retail'].copy()\n",
    "\n",
    "office.spatial.to_featureclass(location=os.path.join(scratch, 'office'),sanitize_columns=False)\n",
    "group_quarters.spatial.to_featureclass(location=os.path.join(scratch, 'group_quarters'),sanitize_columns=False)\n",
    "retail.spatial.to_featureclass(location=os.path.join(scratch, 'retail'),sanitize_columns=False)\n",
    "\n",
    "hui_sdf = hui_sdf[~(hui_sdf['TYPE_WFRC'] == 'office')].copy()\n",
    "hui_sdf = hui_sdf[~(hui_sdf['TYPE_WFRC'] == 'group_quarters')].copy()\n",
    "hui_sdf = hui_sdf[~(hui_sdf['TYPE_WFRC'] == 'retail')].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 26)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parcels that had duplicate addr pts\n",
    "parcels_duplicate_addr_pts = hui_sdf[(hui_sdf['ADJUSTED'].str.contains('Dupli') == True)|\n",
    "                                     (hui_sdf['ADJUSTED'].str.contains('dupli') == True)].copy()\n",
    "\n",
    "parcels_duplicate_addr_pts.spatial.to_featureclass(location=os.path.join(scratch, 'parcels_duplicate_addr_pts'),sanitize_columns=False)\n",
    "parcels_duplicate_addr_pts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Projects\\\\Housing-Unit-Inventory\\\\Outputs\\\\scratch_rp.gdb\\\\wfrc_housing_unit_inventory_20211101_draft'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set total market value to zero\n",
    "hui_sdf['TOTAL_MKT_VALUE'] = np.nan\n",
    "hui_sdf['BLDG_SQFT'] = np.nan\n",
    "\n",
    "hui_sdf.spatial.to_featureclass(location=os.path.join(scratch, 'wfrc_housing_unit_inventory_20211101_draft'),\n",
    "                                sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update attributes\n",
    "hui = os.path.join(scratch, 'wfrc_housing_unit_inventory_20211101_draft')\n",
    "\n",
    "# perform spatial join with within query and sum total market value\n",
    "weber_parcels = r'.\\2020-Weber\\Inputs\\Utah_weber_County_Parcels_LIR.gdb\\Parcels_Weber_LIR_UTM12'\n",
    "davis_parcels = r'.\\2020-Davis\\Inputs\\Davis_County_LIR_Parcels.gdb\\Parcels_Davis_LIR_UTM12'\n",
    "sl_parcels = r'.\\2020-SaltLake\\Inputs\\Utah_Salt_Lake_County_Parcels_LIR.gdb\\Parcels_SaltLake_LIR_UTM12'\n",
    "\n",
    "# merge all parcels for sj\n",
    "merged_parcels = arcpy.Merge_management([weber_parcels, davis_parcels, sl_parcels], os.path.join(scratch, 'merged_parcels'))\n",
    "\n",
    "merged_parcels_pts = arcpy.FeatureToPoint_management(merged_parcels, os.path.join(scratch, 'merged_parcels_pts'), \"INSIDE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spatial join to recalc market value and bldg sqft\n",
    "target_features = hui\n",
    "join_features = merged_parcels_pts\n",
    "output_features = os.path.join(scratch, \"hui_parcels_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "# total market value\n",
    "fieldindex = fieldmappings.findFieldMapIndex('TOTAL_MKT_VALUE')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'Sum'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# building square ft\n",
    "fieldindex = fieldmappings.findFieldMapIndex('BLDG_SQFT')\n",
    "fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "fieldmap.mergeRule = 'Sum'\n",
    "fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "sj = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_COMMON\", \n",
    "                           fieldmappings, \"INTERSECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391713, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load sj as sdf and format\n",
    "sj_sdf = pd.DataFrame.spatial.from_featureclass(sj)\n",
    "sj_sdf = sj_sdf[['UNIT_ID','TOTAL_MKT_VALUE','BLDG_SQFT']].copy()\n",
    "sj_sdf.columns = ['UNIT_ID','TOTAL_MKT_VALUE_NEW','BLDG_SQFT_NEW']\n",
    "sj_sdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add geographies back\n",
    "cities = r'.\\Geographies\\Cities.shp'\n",
    "counties = r'.\\Geographies\\Counties.shp'\n",
    "subcounties = r'.\\Geographies\\SubCountyArea_2019.shp'\n",
    "\n",
    "geographies = [(counties,'COUNTY'),(subcounties, 'SUBCOUNTY'),(cities, 'CITY')]\n",
    "\n",
    "for geog in geographies:\n",
    "    \n",
    "    # use spatial join to summarize res units\n",
    "    target_features = hui\n",
    "    join_features = geog[0]\n",
    "    output_features = os.path.join(scratch, \"hui_{}\".format(geog[1]))\n",
    "\n",
    "    fieldmappings = arcpy.FieldMappings()\n",
    "    fieldmappings.addTable(target_features)\n",
    "    fieldmappings.addTable(join_features)\n",
    "\n",
    "    # run the spatial join\n",
    "    sj2 = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_ALL\", \n",
    "                               fieldmappings, \"WITHIN\")\n",
    "    \n",
    "    sj2_sdf = pd.DataFrame.spatial.from_featureclass(sj2)\n",
    "    sj2_sdf = sj2_sdf[['UNIT_ID','NAME']].copy()\n",
    "    sj2_sdf.columns = ['UNIT_ID', geog[1]]\n",
    "    hui_sdf = hui_sdf.merge(sj2_sdf, left_on = 'UNIT_ID', right_on = 'UNIT_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring back tmv and bldg sqft attributes\n",
    "new_hui = hui_sdf.merge(sj_sdf, left_on = 'UNIT_ID', right_on = 'UNIT_ID', how='left')\n",
    "new_hui['TOTAL_MKT_VALUE'] = new_hui['TOTAL_MKT_VALUE_NEW']\n",
    "new_hui['BLDG_SQFT'] = new_hui['BLDG_SQFT_NEW']\n",
    "\n",
    "del new_hui['TOTAL_MKT_VALUE_NEW']\n",
    "del new_hui['BLDG_SQFT_NEW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalc built decade\n",
    "new_hui.loc[(new_hui['BUILT_YR'] >= 1840) & (new_hui['BUILT_YR'] < 1850), 'BUILT_DECADE'] = \"1840's\"\n",
    "new_hui.loc[(new_hui['BUILT_YR'] >= 1850) & (new_hui['BUILT_YR'] < 1860), 'BUILT_DECADE'] = \"1850's\"\n",
    "new_hui.loc[(new_hui['BUILT_YR'] >= 1860) & (new_hui['BUILT_YR'] < 1870), 'BUILT_DECADE'] = \"1860's\"\n",
    "new_hui.loc[(new_hui['BUILT_YR'] >= 1870) & (new_hui['BUILT_YR'] < 1880), 'BUILT_DECADE'] = \"1870's\"\n",
    "new_hui.loc[(new_hui['BUILT_YR'] >= 1880) & (new_hui['BUILT_YR'] < 1890), 'BUILT_DECADE'] = \"1880's\"\n",
    "new_hui.loc[(new_hui['BUILT_YR'] >= 1890) & (new_hui['BUILT_YR'] < 1900), 'BUILT_DECADE'] = \"1890's\"\n",
    "new_hui.loc[(new_hui['BUILT_YR'] >= 1900) & (new_hui['BUILT_YR'] < 1910), 'BUILT_DECADE'] = \"1900's\"\n",
    "new_hui.loc[(new_hui['BUILT_YR'] >= 1910) & (new_hui['BUILT_YR'] < 1920), 'BUILT_DECADE'] = \"1910's\"\n",
    "new_hui.loc[(new_hui['BUILT_YR'] >= 1920) & (new_hui['BUILT_YR'] < 1930), 'BUILT_DECADE'] = \"1920's\"\n",
    "new_hui.loc[(new_hui['BUILT_YR'] >= 1930) & (new_hui['BUILT_YR'] < 1940), 'BUILT_DECADE'] = \"1930's\"\n",
    "new_hui.loc[(new_hui['BUILT_YR'] >= 1940) & (new_hui['BUILT_YR'] < 1950), 'BUILT_DECADE'] = \"1940's\"\n",
    "new_hui.loc[(new_hui['BUILT_YR'] >= 1950) & (new_hui['BUILT_YR'] < 1960), 'BUILT_DECADE'] = \"1950's\"\n",
    "new_hui.loc[(new_hui['BUILT_YR'] >= 1960) & (new_hui['BUILT_YR'] < 1970), 'BUILT_DECADE'] = \"1960's\"\n",
    "new_hui.loc[(new_hui['BUILT_YR'] >= 1970) & (new_hui['BUILT_YR'] < 1980), 'BUILT_DECADE'] = \"1970's\"\n",
    "new_hui.loc[(new_hui['BUILT_YR'] >= 1980) & (new_hui['BUILT_YR'] < 1990), 'BUILT_DECADE'] = \"1980's\"\n",
    "new_hui.loc[(new_hui['BUILT_YR'] >= 1990) & (new_hui['BUILT_YR'] < 2000), 'BUILT_DECADE'] = \"1990's\"\n",
    "new_hui.loc[(new_hui['BUILT_YR'] >= 2000) & (new_hui['BUILT_YR'] < 2010), 'BUILT_DECADE'] = \"2000's\"\n",
    "new_hui.loc[(new_hui['BUILT_YR'] >= 2010) & (new_hui['BUILT_YR'] < 2020), 'BUILT_DECADE'] = \"2010's\"\n",
    "new_hui.loc[(new_hui['BUILT_YR'] >= 2020) & (new_hui['BUILT_YR'] < 2030), 'BUILT_DECADE'] = \"2020's\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_hui = new_hui[[ 'PARCEL_ID', 'TYPE_WFRC', 'SUBTYPE_WFRC', 'NOTE', 'IS_OUG',\n",
    "       'CITY_x', 'COUNTY_x', 'SUBCOUNTY', 'HOUSE_CNT', 'ADDR_CNT',\n",
    "       'UNIT_COUNT', 'PARCEL_COUNT', 'DUA', 'FLOORS_CNT',\n",
    "       'PARCEL_ACRES', 'BLDG_SQFT', 'TOTAL_MKT_VALUE', 'BUILT_YR',\n",
    "       'BUILT_DECADE', 'UNIT_ID', 'SHAPE']].copy()\n",
    "\n",
    "new_hui = new_hui.rename(columns={'CITY_x': 'CITY'})\n",
    "new_hui = new_hui.rename(columns={'COUNTY_x': 'COUNTY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalc max dua\n",
    "new_hui['DUA'] = (new_hui['UNIT_COUNT'] / new_hui['PARCEL_ACRES']).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Projects\\\\Housing-Unit-Inventory\\\\Outputs\\\\wfrc_hui_20211101.gdb\\\\wfrc_housing_unit_inventory_20211101'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export to shape\n",
    "new_hui.spatial.to_featureclass(location=os.path.join(gdb, 'wfrc_housing_unit_inventory_20211101'),sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read in taz households\n",
    "# taz = r\".\\Outputs\\wfrc_hui_20211025.gdb\\taz_projections_hui_sj_wfrc\"\n",
    "# taz_sdf = pd.DataFrame.spatial.from_featureclass(taz)\n",
    "# taz_sdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taz_sdf = taz_sdf[['CityArea', 'ModelArea', 'CO_TAZID', 'DEVACRES', 'CO_FIPS', 'CO_NAME', 'TAZID', 'RELEASE',\n",
    "#                    'YEAR2019','UNIT_COUNT', 'HUI', 'SHAPE']].copy()\n",
    "\n",
    "# taz_sdf = taz_sdf.rename(columns={\"YEAR2019\": \"REMM_2019\"})\n",
    "# taz_sdf = taz_sdf.rename(columns={\"UNIT_COUNT\": \"HUI_2019\"})\n",
    "\n",
    "\n",
    "# # positive indicates REMM overpredicted, negative REMM indicates underpredicted\n",
    "# taz_sdf['HH19_DIFF'] = taz_sdf['REMM_2019'] - taz_sdf['HUI_2019']\n",
    "# taz_sdf['HH19_PCT_DIFF'] = taz_sdf['HH19_DIFF'] / taz_sdf['HUI_2019'] * 100\n",
    "\n",
    "\n",
    "# taz_sdf.spatial.to_featureclass(location=os.path.join(gdb, 'remm_vs_hui_taz'),sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summarize by city - positive indicates REMM overpredicted, negative REMM indicates underpredicted\n",
    "# city_summary = taz_sdf.groupby('CityArea')[[\"REMM_2019\",'HUI_2019']].sum().reset_index()\n",
    "# city_summary['HH19_DIFF'] = city_summary['REMM_2019'] - city_summary['HUI_2019']\n",
    "# city_summary['HH19_PCT_DIFF'] = city_summary['HH19_DIFF'] / city_summary['HUI_2019'] *100\n",
    "# city_summary.to_csv(os.path.join(outputs, 'hh_city_summary.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summarize by county - positive indicates REMM overpredicted, negative REMM indicates underpredicted\n",
    "# county_summary = taz_sdf.groupby('CO_NAME')[[\"REMM_2019\",'HUI_2019']].sum().reset_index()\n",
    "# county_summary['HH19_DIFF'] = county_summary['REMM_2019'] - county_summary['HUI_2019']\n",
    "# county_summary['HH19_PCT_DIFF'] = county_summary['HH19_DIFF'] / county_summary['HUI_2019'] * 100\n",
    "# county_summary.to_csv(os.path.join(outputs, 'hh_county_summary.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
